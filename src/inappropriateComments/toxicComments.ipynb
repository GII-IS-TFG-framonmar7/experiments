{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#84b6f4;\">Detección de comentarios tóxicos</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#77dd77;\">Formación del DataFrame</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, trataremos de detectar comentarios tóxicos. En primer lugar, sacamos los datos del corpus de entrenamiento en formato parquet y formamos un DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  has_toxic\n",
      "0  Un poco solitario aquí no parece tener muchos ...          0\n",
      "1  @ManuelViloria ¡Gracias!Estoy un poco asustado...          0\n",
      "2  txt chat con Jake lmfao it frikkinawesomei ech...          0\n",
      "3  Soy un estudiante de primer año en la universi...          0\n",
      "4  espera montón de videos aprender idiomas sueño...          0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Función para leer y transformar un archivo Parquet.\n",
    "def read_and_transform(parquet_path):\n",
    "    df = pd.read_parquet(parquet_path)\n",
    "    columns_of_interest = [col for col in df.columns if col == 'text' or col == 'has_toxic']\n",
    "    df = df[columns_of_interest]\n",
    "    return df\n",
    "\n",
    "# Especificamos los archivos Parquet utilizando os.path.join.\n",
    "parquet_files = ['0000.parquet', '0001.parquet', '0002.parquet']\n",
    "data_frames = []\n",
    "\n",
    "for file_name in parquet_files:\n",
    "    file_path = os.path.join(os.getcwd(), 'resources', file_name)\n",
    "    data_frames.append(read_and_transform(file_path))\n",
    "\n",
    "# Concatenamos todos los DataFrames.\n",
    "concatenated_data_frame = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Mostramos las primeras filas del DataFrame balanceado.\n",
    "print(concatenated_data_frame.head(5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#77dd77;\">Entrenamiento</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionamos las métricas que usaremos para predecir, así como el atributo objetivo que, en este caso, será numérico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtramos el DataFrame para obtener las muestras con has_toxic = 1\n",
    "toxic_df = concatenated_data_frame[concatenated_data_frame['has_toxic'] == 1].sample(n=20000, random_state=42)\n",
    "\n",
    "# Filtramos el DataFrame para obtener las muestras con has_toxic = 0\n",
    "non_toxic_df = concatenated_data_frame[concatenated_data_frame['has_toxic'] == 0].sample(n=20000, random_state=42)\n",
    "\n",
    "# Concatenamos los DataFrames balanceados\n",
    "balanced_df = pd.concat([toxic_df, non_toxic_df], ignore_index=True)\n",
    "\n",
    "# Mezclamos las muestras para asegurar un orden aleatorio\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Atributo que usaremos para predecir\n",
    "text = balanced_df['text']\n",
    "\n",
    "# Atributo objetivo a predecir\n",
    "goal = balanced_df['has_toxic']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, entrenamos un modelo de clasificación con una red neuronal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo en el conjunto de prueba: 0.84825\n",
      "F1-Score del modelo: 0.8464975132765742\n",
      "[[5158  842]\n",
      " [ 979 5021]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento (70%) y prueba (30%)\n",
    "attributes_train, attributes_test, goal_train, goal_test = train_test_split(text, goal, test_size=0.3, random_state=42)\n",
    "\n",
    "# Creamos un vectorizador de texto\n",
    "vectorizer = CountVectorizer()\n",
    "attributes_train_vectorized = vectorizer.fit_transform(attributes_train)\n",
    "attributes_test_vectorized = vectorizer.transform(attributes_test)\n",
    "\n",
    "# Entrenamos el modelo de clasificación de redes neuronales\n",
    "toxic_classifier = MLPClassifier(hidden_layer_sizes=(50, 50, 50), activation='relu', solver='adam', random_state=42, max_iter=1000)\n",
    "toxic_classifier.fit(attributes_train_vectorized, goal_train)\n",
    "\n",
    "# Realizamos predicciones con el conjunto de prueba\n",
    "prediction = toxic_classifier.predict(attributes_test_vectorized)\n",
    "\n",
    "# Calculamos la precisión y F1-Score del modelo\n",
    "accuracy = accuracy_score(goal_test, prediction)\n",
    "f1 = f1_score(goal_test, prediction)\n",
    "print(\"Precisión del modelo en el conjunto de prueba:\", accuracy)\n",
    "print(\"F1-Score del modelo:\", f1)\n",
    "\n",
    "# Mostramos la matriz de confusión\n",
    "print(confusion_matrix(goal_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos el modelo con algunos ejemplos concretos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El comentario 'Me encanta la peli.' NO es tóxico.\n",
      "El comentario 'Ya hay que ser idiota para pensar así...' es tóxico.\n",
      "El comentario 'Te felicito por tu trabajo; sin embargo, tienes que mejorar tu oratoria.' NO es tóxico.\n",
      "El comentario 'Eres un tío genial.' es tóxico.\n",
      "El comentario 'Te quiero, pero eres una basura.' es tóxico.\n"
     ]
    }
   ],
   "source": [
    "message = [\"NO es tóxico\", \"es tóxico\"]\n",
    "\n",
    "# Texto de ejemplo 1\n",
    "example_text_1 = \"Me encanta la peli.\"\n",
    "example_text_1_vectorized = vectorizer.transform([example_text_1])\n",
    "\n",
    "# Texto de ejemplo 2\n",
    "example_text_2 = \"Ya hay que ser idiota para pensar así...\"\n",
    "example_text_2_vectorized = vectorizer.transform([example_text_2])\n",
    "\n",
    "# Texto de ejemplo 3\n",
    "example_text_3 = \"Te felicito por tu trabajo; sin embargo, tienes que mejorar tu oratoria.\"\n",
    "example_text_3_vectorized = vectorizer.transform([example_text_3])\n",
    "\n",
    "# Texto de ejemplo 4\n",
    "example_text_4 = \"Eres un tío genial.\"\n",
    "example_text_4_vectorized = vectorizer.transform([example_text_4])\n",
    "\n",
    "# Texto de ejemplo 5\n",
    "example_text_5 = \"Te quiero, pero eres una basura.\"\n",
    "example_text_5_vectorized = vectorizer.transform([example_text_5])\n",
    "\n",
    "print(\"El comentario '\" + example_text_1 + \"' \" + message[toxic_classifier.predict(example_text_1_vectorized)[0]] + \".\")\n",
    "print(\"El comentario '\" + example_text_2 + \"' \" + message[toxic_classifier.predict(example_text_2_vectorized)[0]] + \".\")\n",
    "print(\"El comentario '\" + example_text_3 + \"' \" + message[toxic_classifier.predict(example_text_3_vectorized)[0]] + \".\")\n",
    "print(\"El comentario '\" + example_text_4 + \"' \" + message[toxic_classifier.predict(example_text_4_vectorized)[0]] + \".\")\n",
    "print(\"El comentario '\" + example_text_5 + \"' \" + message[toxic_classifier.predict(example_text_5_vectorized)[0]] + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar, exportamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toxic_vectorizer.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Guardamos el modelo\n",
    "model_filename = 'toxic_classifier.joblib'\n",
    "dump(toxic_classifier, model_filename)\n",
    "\n",
    "# Guardamos el vectorizador\n",
    "vectorizer_filename = 'toxic_vectorizer.joblib'\n",
    "dump(vectorizer, vectorizer_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
