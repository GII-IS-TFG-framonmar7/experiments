{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#84b6f4;\">Estudio para despejar incógnitas del enfoque  1-1</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El último experimento realizado, que se utilizó para seleccionar la arquitectura más conveniente, trajo consigo varias respuestas pero también algunas preguntas. Este estudio pretende despejar las incógnitas y comprobar si el modelo realmente aprende lo que debe aprender.\n",
    "\n",
    "Al haber entrenado un mismo modelo con las imágenes de tres actores diferentes, se plantea la duda de si los resultados, que parecen ser un tanto impredecibles, se deben a que el modelo \"reutiliza\" características de entrenamientos previos y lleva a resultados engañosos, como puede ser que intente detectar a alguno de los actores para los que ha sido entrenado previamente o similar. Para ello, sería conveniente modificar el orden de entrenamiento; el modelo será entrenado con las imágenes de Bella Ramsey, Will Smith y Pedro Pascal, en ese orden. De esa forma se podrá comprobar si existe algún patrón relacionado con el orden. Además, una vez que el modelo haya sido entrenado y evaluado para los tres actores, se volverá a hacer la predicción con los actores para los que el modelo ha sido entrenado previamente, para ver si los resultados son altos, con el objetivo de comprobar si el modelo \"olvida\" los entrenamientos previos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#77dd77;\">Creación del modelo</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que en el experimento anterior, trataremos de identificar a Bella Ramsey, Will Smith y Pedro Pascal utilizando el enfoque 1-1, pero en un orden diferente para ver si se mantiene el patrón en los resultados para cada actor. Comenzamos creando los DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Directorios en los que se encuentran las imágenes\n",
    "pedro_directory = os.getcwd() + '/resources/actorImages/pedroPascal'\n",
    "bella_directory = os.getcwd() + '/resources/actorImages/bellaRamsey'\n",
    "will_directory = os.getcwd() + '/resources/actorImages/willSmith'\n",
    "other_actors_directory = os.getcwd() + '/resources/actorImages/otherActors'\n",
    "\n",
    "pedro_data = []\n",
    "bella_data = []\n",
    "will_data = []\n",
    "\n",
    "# Añadimos imágenes en las que aparece Pedro Pascal (e imágenes en las que no)\n",
    "for image in os.listdir(pedro_directory):\n",
    "    image_url = os.path.join(pedro_directory, image)\n",
    "    pedro_data.append({\"image\": image_url, \"pedro_pascal\": 1})\n",
    "\n",
    "other_actor_images = os.listdir(other_actors_directory)[:150]\n",
    "for image in other_actor_images:\n",
    "    image_url = os.path.join(other_actors_directory, image)\n",
    "    pedro_data.append({\"image\": image_url, \"pedro_pascal\": 0})\n",
    "\n",
    "# Añadimos imágenes en las que aparece Bella Ramsey (e imágenes en las que no)\n",
    "for image in os.listdir(bella_directory):\n",
    "    image_url = os.path.join(bella_directory, image)\n",
    "    bella_data.append({\"image\": image_url, \"bella_ramsey\": 1})\n",
    "\n",
    "for image in other_actor_images:\n",
    "    image_url = os.path.join(other_actors_directory, image)\n",
    "    bella_data.append({\"image\": image_url, \"bella_ramsey\": 0})\n",
    "\n",
    "# Añadimos imágenes en las que aparece Will Smith (e imágenes en las que no)\n",
    "will_images = os.listdir(will_directory)[:150]\n",
    "for image in will_images:\n",
    "    image_url = os.path.join(will_directory, image)\n",
    "    will_data.append({\"image\": image_url, \"will_smith\": 1})\n",
    "\n",
    "for image in other_actor_images:\n",
    "    image_url = os.path.join(other_actors_directory, image)\n",
    "    will_data.append({\"image\": image_url, \"will_smith\": 0})\n",
    "\n",
    "# Desordenamos aleatoriamente los datos\n",
    "random.shuffle(pedro_data)\n",
    "random.shuffle(bella_data)\n",
    "random.shuffle(will_data)\n",
    "\n",
    "# Creamos los DataFrames\n",
    "pedro_df = pd.DataFrame(pedro_data)\n",
    "bella_df = pd.DataFrame(bella_data)\n",
    "will_df = pd.DataFrame(will_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos las imágenes de entrada (los píxeles) y las etiquetas asociadas a cada imagen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedro_images = []; pedro_labels = []\n",
    "bella_images = []; bella_labels = []\n",
    "will_images = []; will_labels = []\n",
    "\n",
    "IMG_SIZE = 100\n",
    "\n",
    "# Cargamos las imágenes del DataFrame de Pedro Pascal\n",
    "for i, row in pedro_df.iterrows():\n",
    "    image_url = row['image']\n",
    "    image = cv2.imread(image_url)\n",
    "    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = image.reshape(IMG_SIZE, IMG_SIZE, 1)\n",
    "    pedro_images.append(image)\n",
    "    pedro_labels.append(row['pedro_pascal'])\n",
    "\n",
    "# Cargamos las imágenes del DataFrame de Bella Ramsey\n",
    "for i, row in bella_df.iterrows():\n",
    "    image_url = row['image']\n",
    "    image = cv2.imread(image_url)\n",
    "    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = image.reshape(IMG_SIZE, IMG_SIZE, 1)\n",
    "    bella_images.append(image)\n",
    "    bella_labels.append(row['bella_ramsey'])\n",
    "\n",
    "# Cargamos las imágenes del DataFrame de Will Smith\n",
    "for i, row in will_df.iterrows():\n",
    "    image_url = row['image']\n",
    "    image = cv2.imread(image_url)\n",
    "    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = image.reshape(IMG_SIZE, IMG_SIZE, 1)\n",
    "    will_images.append(image)\n",
    "    will_labels.append(row['will_smith'])\n",
    "\n",
    "pedro_images = np.array(pedro_images).astype(float)/255; pedro_labels = np.array(pedro_labels)\n",
    "bella_images = np.array(bella_images).astype(float)/255; bella_labels = np.array(bella_labels)\n",
    "will_images = np.array(will_images).astype(float)/255; will_labels = np.array(will_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos transformaciones de aumento de datos a las imágenes, para volver el conjunto de datos más diverso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Creamos un generador de imágenes aumentadas\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=15,\n",
    "    zoom_range=[0.7, 1.4],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "datagen.fit(pedro_images)\n",
    "datagen.fit(bella_images)\n",
    "datagen.fit(will_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un modelo de red neuronal convolucional (CNN) y lo entrenamos con las imágenes del DataFrame de Bella Ramsey:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7/7 [==============================] - 2s 207ms/step - loss: 0.7085 - accuracy: 0.4857 - val_loss: 0.6913 - val_accuracy: 0.5111\n",
      "Epoch 2/60\n",
      "7/7 [==============================] - 1s 189ms/step - loss: 0.6873 - accuracy: 0.5524 - val_loss: 0.6891 - val_accuracy: 0.5000\n",
      "Epoch 3/60\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 0.6775 - accuracy: 0.5714 - val_loss: 0.6917 - val_accuracy: 0.5111\n",
      "Epoch 4/60\n",
      "7/7 [==============================] - 1s 190ms/step - loss: 0.6537 - accuracy: 0.5667 - val_loss: 0.6603 - val_accuracy: 0.5556\n",
      "Epoch 5/60\n",
      "7/7 [==============================] - 1s 192ms/step - loss: 0.6431 - accuracy: 0.6619 - val_loss: 0.6473 - val_accuracy: 0.6444\n",
      "Epoch 6/60\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.6191 - accuracy: 0.6714 - val_loss: 0.7138 - val_accuracy: 0.5667\n",
      "Epoch 7/60\n",
      "7/7 [==============================] - 1s 178ms/step - loss: 0.6356 - accuracy: 0.6381 - val_loss: 0.6410 - val_accuracy: 0.6333\n",
      "Epoch 8/60\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.6077 - accuracy: 0.6952 - val_loss: 0.6166 - val_accuracy: 0.6667\n",
      "Epoch 9/60\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.5643 - accuracy: 0.7524 - val_loss: 0.5931 - val_accuracy: 0.7222\n",
      "Epoch 10/60\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.5868 - accuracy: 0.6667 - val_loss: 0.6285 - val_accuracy: 0.7000\n",
      "Epoch 11/60\n",
      "7/7 [==============================] - 1s 183ms/step - loss: 0.6122 - accuracy: 0.6762 - val_loss: 0.5926 - val_accuracy: 0.7222\n",
      "Epoch 12/60\n",
      "7/7 [==============================] - 1s 183ms/step - loss: 0.5746 - accuracy: 0.6905 - val_loss: 0.6256 - val_accuracy: 0.6889\n",
      "Epoch 13/60\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 0.5702 - accuracy: 0.7000 - val_loss: 0.5887 - val_accuracy: 0.7111\n",
      "Epoch 14/60\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.5907 - accuracy: 0.7000 - val_loss: 0.5889 - val_accuracy: 0.7000\n",
      "Epoch 15/60\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.5850 - accuracy: 0.7143 - val_loss: 0.5806 - val_accuracy: 0.7111\n",
      "Epoch 16/60\n",
      "7/7 [==============================] - 1s 178ms/step - loss: 0.5494 - accuracy: 0.7048 - val_loss: 0.5629 - val_accuracy: 0.7444\n",
      "Epoch 17/60\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 0.5923 - accuracy: 0.7238 - val_loss: 0.5986 - val_accuracy: 0.6889\n",
      "Epoch 18/60\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.5431 - accuracy: 0.7381 - val_loss: 0.5738 - val_accuracy: 0.7333\n",
      "Epoch 19/60\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.5487 - accuracy: 0.7286 - val_loss: 0.5663 - val_accuracy: 0.7556\n",
      "Epoch 20/60\n",
      "7/7 [==============================] - 1s 178ms/step - loss: 0.5339 - accuracy: 0.7143 - val_loss: 0.5567 - val_accuracy: 0.7444\n",
      "Epoch 21/60\n",
      "7/7 [==============================] - 1s 178ms/step - loss: 0.5494 - accuracy: 0.7095 - val_loss: 0.5874 - val_accuracy: 0.7111\n",
      "Epoch 22/60\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 0.5270 - accuracy: 0.7524 - val_loss: 0.5611 - val_accuracy: 0.7333\n",
      "Epoch 23/60\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 0.5369 - accuracy: 0.7238 - val_loss: 0.5738 - val_accuracy: 0.7222\n",
      "Epoch 24/60\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 0.5397 - accuracy: 0.7190 - val_loss: 0.5731 - val_accuracy: 0.7778\n",
      "Epoch 25/60\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 0.5551 - accuracy: 0.7095 - val_loss: 0.6566 - val_accuracy: 0.6444\n",
      "Epoch 26/60\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.5333 - accuracy: 0.6952 - val_loss: 0.5896 - val_accuracy: 0.6889\n",
      "Epoch 27/60\n",
      "7/7 [==============================] - 1s 178ms/step - loss: 0.5470 - accuracy: 0.7476 - val_loss: 0.6465 - val_accuracy: 0.6556\n",
      "Epoch 28/60\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 0.5231 - accuracy: 0.7238 - val_loss: 0.5858 - val_accuracy: 0.7444\n",
      "Epoch 29/60\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.5238 - accuracy: 0.7381 - val_loss: 0.6031 - val_accuracy: 0.7333\n",
      "Epoch 30/60\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.5056 - accuracy: 0.7619 - val_loss: 0.5546 - val_accuracy: 0.7333\n",
      "Epoch 31/60\n",
      "7/7 [==============================] - 1s 178ms/step - loss: 0.5132 - accuracy: 0.7476 - val_loss: 0.5528 - val_accuracy: 0.7444\n",
      "Epoch 32/60\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 0.5183 - accuracy: 0.7381 - val_loss: 0.5629 - val_accuracy: 0.7556\n",
      "Epoch 33/60\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.5470 - accuracy: 0.7333 - val_loss: 0.5744 - val_accuracy: 0.7556\n",
      "Epoch 34/60\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.5799 - accuracy: 0.7048 - val_loss: 0.6609 - val_accuracy: 0.6556\n",
      "Epoch 35/60\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.5362 - accuracy: 0.7571 - val_loss: 0.5640 - val_accuracy: 0.7333\n",
      "Epoch 36/60\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 0.5361 - accuracy: 0.7286 - val_loss: 0.6884 - val_accuracy: 0.6778\n",
      "Epoch 37/60\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.5089 - accuracy: 0.7571 - val_loss: 0.5569 - val_accuracy: 0.7556\n",
      "Epoch 38/60\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.5324 - accuracy: 0.7571 - val_loss: 0.7270 - val_accuracy: 0.6444\n",
      "Epoch 39/60\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.5334 - accuracy: 0.7333 - val_loss: 0.5760 - val_accuracy: 0.7222\n",
      "Epoch 40/60\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.5228 - accuracy: 0.6905 - val_loss: 0.6671 - val_accuracy: 0.6444\n",
      "Epoch 41/60\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 0.5204 - accuracy: 0.7381 - val_loss: 0.5546 - val_accuracy: 0.7333\n",
      "Epoch 42/60\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.5021 - accuracy: 0.7524 - val_loss: 0.5726 - val_accuracy: 0.7667\n",
      "Epoch 43/60\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.5048 - accuracy: 0.7429 - val_loss: 0.6144 - val_accuracy: 0.7222\n",
      "Epoch 44/60\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.5423 - accuracy: 0.7476 - val_loss: 0.5584 - val_accuracy: 0.7333\n",
      "Epoch 45/60\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 0.4937 - accuracy: 0.7714 - val_loss: 0.5600 - val_accuracy: 0.7444\n",
      "Epoch 46/60\n",
      "7/7 [==============================] - 1s 186ms/step - loss: 0.5165 - accuracy: 0.7286 - val_loss: 0.5679 - val_accuracy: 0.7556\n",
      "Epoch 47/60\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 0.5169 - accuracy: 0.7524 - val_loss: 0.5540 - val_accuracy: 0.7556\n",
      "Epoch 48/60\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 0.4922 - accuracy: 0.7619 - val_loss: 0.5686 - val_accuracy: 0.7444\n",
      "Epoch 49/60\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 0.4985 - accuracy: 0.7571 - val_loss: 0.5755 - val_accuracy: 0.7444\n",
      "Epoch 50/60\n",
      "7/7 [==============================] - 1s 190ms/step - loss: 0.4913 - accuracy: 0.8000 - val_loss: 0.5627 - val_accuracy: 0.7222\n",
      "Epoch 51/60\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.6155 - accuracy: 0.6857 - val_loss: 0.6218 - val_accuracy: 0.7000\n",
      "Epoch 52/60\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 0.5812 - accuracy: 0.7000 - val_loss: 0.5506 - val_accuracy: 0.7000\n",
      "Epoch 53/60\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 0.5291 - accuracy: 0.7714 - val_loss: 0.5367 - val_accuracy: 0.7444\n",
      "Epoch 54/60\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.5185 - accuracy: 0.7619 - val_loss: 0.5603 - val_accuracy: 0.7222\n",
      "Epoch 55/60\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 0.5139 - accuracy: 0.7571 - val_loss: 0.6666 - val_accuracy: 0.6667\n",
      "Epoch 56/60\n",
      "7/7 [==============================] - 1s 196ms/step - loss: 0.5063 - accuracy: 0.7286 - val_loss: 0.5661 - val_accuracy: 0.7222\n",
      "Epoch 57/60\n",
      "7/7 [==============================] - 1s 195ms/step - loss: 0.5052 - accuracy: 0.7333 - val_loss: 0.5660 - val_accuracy: 0.7111\n",
      "Epoch 58/60\n",
      "7/7 [==============================] - 1s 204ms/step - loss: 0.4986 - accuracy: 0.7429 - val_loss: 0.5466 - val_accuracy: 0.7222\n",
      "Epoch 59/60\n",
      "7/7 [==============================] - 1s 195ms/step - loss: 0.5121 - accuracy: 0.7476 - val_loss: 0.5525 - val_accuracy: 0.7222\n",
      "Epoch 60/60\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 0.5178 - accuracy: 0.7524 - val_loss: 0.6006 - val_accuracy: 0.7444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1ca664cf2d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividimos los datos en conjuntos de entrenamiento (70%) y prueba (30%)\n",
    "pedro_train_images, pedro_test_images, pedro_train_labels, pedro_test_labels = train_test_split(pedro_images, pedro_labels, test_size=0.3, random_state=42)\n",
    "bella_train_images, bella_test_images, bella_train_labels, bella_test_labels = train_test_split(bella_images, bella_labels, test_size=0.3, random_state=42)\n",
    "will_train_images, will_test_images, will_train_labels, will_test_labels = train_test_split(will_images, will_labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Creamos el modelo\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(100, 100, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(250, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Configuramos el modelo para el entrenamiento\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenamos el modelo\n",
    "model.fit(\n",
    "    datagen.flow(bella_train_images, bella_train_labels, batch_size=32),\n",
    "    epochs=60, batch_size=32,\n",
    "    validation_data=(bella_test_images, bella_test_labels),\n",
    "    steps_per_epoch=int(np.ceil(len(bella_train_images) / float(32))),\n",
    "    validation_steps=int(np.ceil(len(bella_test_images) / float(32)))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos los resultados del modelo, utilizando métricas como la precisión, el F1-score y la matriz de confusión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 33ms/step\n",
      "Resultados para Bella:\n",
      "Precisión: 0.7444444444444445\n",
      "F1 Score: 0.7160493827160493\n",
      "Matriz de confusión:\n",
      "[[38  6]\n",
      " [17 29]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# Evaluamos el modelo\n",
    "bella_test_predictions = model.predict(bella_test_images)\n",
    "bella_test_predictions_rounded = np.round(bella_test_predictions)\n",
    "\n",
    "bella_accuracy = accuracy_score(bella_test_labels, bella_test_predictions_rounded)\n",
    "bella_f1 = f1_score(bella_test_labels, bella_test_predictions_rounded)\n",
    "bella_confusion = confusion_matrix(bella_test_labels, bella_test_predictions_rounded)\n",
    "\n",
    "# Mostramos los resultados\n",
    "print(\"Resultados para Bella:\")\n",
    "print(\"Precisión:\", bella_accuracy)\n",
    "print(\"F1 Score:\", bella_f1)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(bella_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo con las imágenes del DataFrame de Will Smith:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7/7 [==============================] - 1s 202ms/step - loss: 0.7935 - accuracy: 0.5714 - val_loss: 0.6172 - val_accuracy: 0.6111\n",
      "Epoch 2/60\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 0.6986 - accuracy: 0.5333 - val_loss: 0.7122 - val_accuracy: 0.5556\n",
      "Epoch 3/60\n",
      "7/7 [==============================] - 1s 199ms/step - loss: 0.6876 - accuracy: 0.5429 - val_loss: 0.7018 - val_accuracy: 0.5222\n",
      "Epoch 4/60\n",
      "7/7 [==============================] - 1s 196ms/step - loss: 0.6707 - accuracy: 0.5762 - val_loss: 0.6661 - val_accuracy: 0.6222\n",
      "Epoch 5/60\n",
      "7/7 [==============================] - 1s 190ms/step - loss: 0.6800 - accuracy: 0.5619 - val_loss: 0.6403 - val_accuracy: 0.6222\n",
      "Epoch 6/60\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.6674 - accuracy: 0.6190 - val_loss: 0.6460 - val_accuracy: 0.6556\n",
      "Epoch 7/60\n",
      "7/7 [==============================] - 1s 195ms/step - loss: 0.6721 - accuracy: 0.5952 - val_loss: 0.6295 - val_accuracy: 0.6333\n",
      "Epoch 8/60\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.6356 - accuracy: 0.6429 - val_loss: 0.6386 - val_accuracy: 0.6222\n",
      "Epoch 9/60\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.6438 - accuracy: 0.6524 - val_loss: 0.6160 - val_accuracy: 0.6778\n",
      "Epoch 10/60\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 0.6529 - accuracy: 0.6000 - val_loss: 0.6111 - val_accuracy: 0.6556\n",
      "Epoch 11/60\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.6594 - accuracy: 0.6143 - val_loss: 0.6158 - val_accuracy: 0.6667\n",
      "Epoch 12/60\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 0.6257 - accuracy: 0.6524 - val_loss: 0.6190 - val_accuracy: 0.6333\n",
      "Epoch 13/60\n",
      "7/7 [==============================] - 1s 204ms/step - loss: 0.6144 - accuracy: 0.6714 - val_loss: 0.6235 - val_accuracy: 0.6111\n",
      "Epoch 14/60\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 0.6443 - accuracy: 0.6333 - val_loss: 0.6229 - val_accuracy: 0.6444\n",
      "Epoch 15/60\n",
      "7/7 [==============================] - 1s 199ms/step - loss: 0.6346 - accuracy: 0.6524 - val_loss: 0.6105 - val_accuracy: 0.6444\n",
      "Epoch 16/60\n",
      "7/7 [==============================] - 1s 194ms/step - loss: 0.6225 - accuracy: 0.6619 - val_loss: 0.6267 - val_accuracy: 0.6222\n",
      "Epoch 17/60\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 0.6156 - accuracy: 0.6571 - val_loss: 0.5985 - val_accuracy: 0.6778\n",
      "Epoch 18/60\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 0.6373 - accuracy: 0.6429 - val_loss: 0.6019 - val_accuracy: 0.6667\n",
      "Epoch 19/60\n",
      "7/7 [==============================] - 1s 204ms/step - loss: 0.6156 - accuracy: 0.6905 - val_loss: 0.6012 - val_accuracy: 0.6667\n",
      "Epoch 20/60\n",
      "7/7 [==============================] - 1s 186ms/step - loss: 0.6359 - accuracy: 0.6667 - val_loss: 0.5961 - val_accuracy: 0.6778\n",
      "Epoch 21/60\n",
      "7/7 [==============================] - 1s 178ms/step - loss: 0.6089 - accuracy: 0.6905 - val_loss: 0.6649 - val_accuracy: 0.6111\n",
      "Epoch 22/60\n",
      "7/7 [==============================] - 1s 189ms/step - loss: 0.6093 - accuracy: 0.6762 - val_loss: 0.6046 - val_accuracy: 0.6889\n",
      "Epoch 23/60\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 0.6314 - accuracy: 0.6524 - val_loss: 0.6465 - val_accuracy: 0.6556\n",
      "Epoch 24/60\n",
      "7/7 [==============================] - 1s 200ms/step - loss: 0.6035 - accuracy: 0.6619 - val_loss: 0.5876 - val_accuracy: 0.6667\n",
      "Epoch 25/60\n",
      "7/7 [==============================] - 1s 190ms/step - loss: 0.5875 - accuracy: 0.6857 - val_loss: 0.6157 - val_accuracy: 0.6333\n",
      "Epoch 26/60\n",
      "7/7 [==============================] - 1s 189ms/step - loss: 0.5784 - accuracy: 0.7143 - val_loss: 0.6203 - val_accuracy: 0.6444\n",
      "Epoch 27/60\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.6182 - accuracy: 0.6429 - val_loss: 0.6096 - val_accuracy: 0.6444\n",
      "Epoch 28/60\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.5937 - accuracy: 0.6857 - val_loss: 0.6172 - val_accuracy: 0.6444\n",
      "Epoch 29/60\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 0.5932 - accuracy: 0.6905 - val_loss: 0.6490 - val_accuracy: 0.6444\n",
      "Epoch 30/60\n",
      "7/7 [==============================] - 1s 195ms/step - loss: 0.6136 - accuracy: 0.6238 - val_loss: 0.5689 - val_accuracy: 0.7333\n",
      "Epoch 31/60\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.5753 - accuracy: 0.6857 - val_loss: 0.7386 - val_accuracy: 0.6000\n",
      "Epoch 32/60\n",
      "7/7 [==============================] - 1s 193ms/step - loss: 0.6751 - accuracy: 0.6095 - val_loss: 0.5814 - val_accuracy: 0.7222\n",
      "Epoch 33/60\n",
      "7/7 [==============================] - 1s 190ms/step - loss: 0.6725 - accuracy: 0.6000 - val_loss: 0.6091 - val_accuracy: 0.6778\n",
      "Epoch 34/60\n",
      "7/7 [==============================] - 1s 178ms/step - loss: 0.6220 - accuracy: 0.6810 - val_loss: 0.6652 - val_accuracy: 0.5889\n",
      "Epoch 35/60\n",
      "7/7 [==============================] - 1s 178ms/step - loss: 0.6349 - accuracy: 0.6429 - val_loss: 0.6190 - val_accuracy: 0.6222\n",
      "Epoch 36/60\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.6075 - accuracy: 0.6857 - val_loss: 0.6188 - val_accuracy: 0.6111\n",
      "Epoch 37/60\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.6194 - accuracy: 0.6810 - val_loss: 0.6426 - val_accuracy: 0.6111\n",
      "Epoch 38/60\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.6134 - accuracy: 0.6476 - val_loss: 0.5959 - val_accuracy: 0.6444\n",
      "Epoch 39/60\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.6190 - accuracy: 0.6524 - val_loss: 0.6143 - val_accuracy: 0.6778\n",
      "Epoch 40/60\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.6182 - accuracy: 0.6381 - val_loss: 0.6067 - val_accuracy: 0.7111\n",
      "Epoch 41/60\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.6069 - accuracy: 0.6619 - val_loss: 0.5969 - val_accuracy: 0.6667\n",
      "Epoch 42/60\n",
      "7/7 [==============================] - 1s 190ms/step - loss: 0.6265 - accuracy: 0.6381 - val_loss: 0.6128 - val_accuracy: 0.6444\n",
      "Epoch 43/60\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 0.5843 - accuracy: 0.6714 - val_loss: 0.5940 - val_accuracy: 0.6667\n",
      "Epoch 44/60\n",
      "7/7 [==============================] - 1s 197ms/step - loss: 0.6166 - accuracy: 0.6524 - val_loss: 0.5949 - val_accuracy: 0.6889\n",
      "Epoch 45/60\n",
      "7/7 [==============================] - 1s 193ms/step - loss: 0.6490 - accuracy: 0.6571 - val_loss: 0.5985 - val_accuracy: 0.6889\n",
      "Epoch 46/60\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.5777 - accuracy: 0.6810 - val_loss: 0.6030 - val_accuracy: 0.6778\n",
      "Epoch 47/60\n",
      "7/7 [==============================] - 1s 213ms/step - loss: 0.5927 - accuracy: 0.7000 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
      "Epoch 48/60\n",
      "7/7 [==============================] - 1s 193ms/step - loss: 0.5944 - accuracy: 0.6762 - val_loss: 0.6113 - val_accuracy: 0.6556\n",
      "Epoch 49/60\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.5645 - accuracy: 0.7571 - val_loss: 0.6499 - val_accuracy: 0.6556\n",
      "Epoch 50/60\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 0.5944 - accuracy: 0.7048 - val_loss: 0.6145 - val_accuracy: 0.6667\n",
      "Epoch 51/60\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.5810 - accuracy: 0.7143 - val_loss: 0.6339 - val_accuracy: 0.6667\n",
      "Epoch 52/60\n",
      "7/7 [==============================] - 1s 189ms/step - loss: 0.6178 - accuracy: 0.6714 - val_loss: 0.6187 - val_accuracy: 0.6556\n",
      "Epoch 53/60\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.5854 - accuracy: 0.7095 - val_loss: 0.6196 - val_accuracy: 0.6444\n",
      "Epoch 54/60\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 0.5610 - accuracy: 0.6810 - val_loss: 0.5972 - val_accuracy: 0.6667\n",
      "Epoch 55/60\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.6071 - accuracy: 0.6905 - val_loss: 0.6083 - val_accuracy: 0.6778\n",
      "Epoch 56/60\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.5936 - accuracy: 0.6667 - val_loss: 0.5900 - val_accuracy: 0.7222\n",
      "Epoch 57/60\n",
      "7/7 [==============================] - 1s 178ms/step - loss: 0.6102 - accuracy: 0.6429 - val_loss: 0.6020 - val_accuracy: 0.6889\n",
      "Epoch 58/60\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.6081 - accuracy: 0.6619 - val_loss: 0.5914 - val_accuracy: 0.7000\n",
      "Epoch 59/60\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 0.5821 - accuracy: 0.6762 - val_loss: 0.5930 - val_accuracy: 0.7000\n",
      "Epoch 60/60\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.5841 - accuracy: 0.6857 - val_loss: 0.5711 - val_accuracy: 0.6889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1ca7093a350>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    datagen.flow(will_train_images, will_train_labels, batch_size=32),\n",
    "    epochs=60, batch_size=32,\n",
    "    validation_data=(will_test_images, will_test_labels),\n",
    "    steps_per_epoch=int(np.ceil(len(will_train_images) / float(32))),\n",
    "    validation_steps=int(np.ceil(len(will_test_images) / float(32)))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos los resultados del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 32ms/step\n",
      "Resultados para Will:\n",
      "Precisión: 0.6888888888888889\n",
      "F1 Score: 0.6888888888888889\n",
      "Matriz de confusión:\n",
      "[[31 12]\n",
      " [16 31]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el modelo\n",
    "will_test_predictions = model.predict(will_test_images)\n",
    "will_test_predictions_rounded = np.round(will_test_predictions)\n",
    "\n",
    "will_accuracy = accuracy_score(will_test_labels, will_test_predictions_rounded)\n",
    "will_f1 = f1_score(will_test_labels, will_test_predictions_rounded)\n",
    "will_confusion = confusion_matrix(will_test_labels, will_test_predictions_rounded)\n",
    "\n",
    "# Mostramos los resultados\n",
    "print(\"Resultados para Will:\")\n",
    "print(\"Precisión:\", will_accuracy)\n",
    "print(\"F1 Score:\", will_f1)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(will_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo con las imágenes del DataFrame de Pedro Pascal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 0.6145 - accuracy: 0.6473 - val_loss: 0.6689 - val_accuracy: 0.6111\n",
      "Epoch 2/60\n",
      "7/7 [==============================] - 1s 197ms/step - loss: 0.6170 - accuracy: 0.6570 - val_loss: 0.6505 - val_accuracy: 0.6111\n",
      "Epoch 3/60\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 0.6435 - accuracy: 0.6618 - val_loss: 0.6946 - val_accuracy: 0.5667\n",
      "Epoch 4/60\n",
      "7/7 [==============================] - 1s 183ms/step - loss: 0.6260 - accuracy: 0.6570 - val_loss: 0.6259 - val_accuracy: 0.6222\n",
      "Epoch 5/60\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.6242 - accuracy: 0.6425 - val_loss: 0.6393 - val_accuracy: 0.5889\n",
      "Epoch 6/60\n",
      "7/7 [==============================] - 1s 183ms/step - loss: 0.6202 - accuracy: 0.6232 - val_loss: 0.6561 - val_accuracy: 0.5778\n",
      "Epoch 7/60\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.6202 - accuracy: 0.6570 - val_loss: 0.6732 - val_accuracy: 0.5556\n",
      "Epoch 8/60\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.5914 - accuracy: 0.6957 - val_loss: 0.6481 - val_accuracy: 0.6000\n",
      "Epoch 9/60\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.6307 - accuracy: 0.6377 - val_loss: 0.6628 - val_accuracy: 0.5556\n",
      "Epoch 10/60\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.5776 - accuracy: 0.7295 - val_loss: 0.6572 - val_accuracy: 0.5667\n",
      "Epoch 11/60\n",
      "7/7 [==============================] - 1s 189ms/step - loss: 0.6378 - accuracy: 0.5942 - val_loss: 0.6475 - val_accuracy: 0.6222\n",
      "Epoch 12/60\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.5845 - accuracy: 0.6522 - val_loss: 0.6605 - val_accuracy: 0.6000\n",
      "Epoch 13/60\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.6227 - accuracy: 0.6473 - val_loss: 0.6330 - val_accuracy: 0.6444\n",
      "Epoch 14/60\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 0.5924 - accuracy: 0.7005 - val_loss: 0.6450 - val_accuracy: 0.5667\n",
      "Epoch 15/60\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.5844 - accuracy: 0.7005 - val_loss: 0.6494 - val_accuracy: 0.5889\n",
      "Epoch 16/60\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.6201 - accuracy: 0.6473 - val_loss: 0.6403 - val_accuracy: 0.6111\n",
      "Epoch 17/60\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.6142 - accuracy: 0.6425 - val_loss: 0.6581 - val_accuracy: 0.6000\n",
      "Epoch 18/60\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.5992 - accuracy: 0.6812 - val_loss: 0.6895 - val_accuracy: 0.5889\n",
      "Epoch 19/60\n",
      "7/7 [==============================] - 1s 190ms/step - loss: 0.5947 - accuracy: 0.6763 - val_loss: 0.6107 - val_accuracy: 0.6556\n",
      "Epoch 20/60\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 0.5849 - accuracy: 0.6812 - val_loss: 0.6154 - val_accuracy: 0.6556\n",
      "Epoch 21/60\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 0.5926 - accuracy: 0.6570 - val_loss: 0.6827 - val_accuracy: 0.6000\n",
      "Epoch 22/60\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.5704 - accuracy: 0.7391 - val_loss: 0.6419 - val_accuracy: 0.6333\n",
      "Epoch 23/60\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.5840 - accuracy: 0.6860 - val_loss: 0.6509 - val_accuracy: 0.6444\n",
      "Epoch 24/60\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.5623 - accuracy: 0.7150 - val_loss: 0.6267 - val_accuracy: 0.6444\n",
      "Epoch 25/60\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 0.5896 - accuracy: 0.6812 - val_loss: 0.6253 - val_accuracy: 0.6333\n",
      "Epoch 26/60\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 0.5995 - accuracy: 0.6522 - val_loss: 0.6099 - val_accuracy: 0.6667\n",
      "Epoch 27/60\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 0.5517 - accuracy: 0.7536 - val_loss: 0.6402 - val_accuracy: 0.6444\n",
      "Epoch 28/60\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 0.5688 - accuracy: 0.7005 - val_loss: 0.6038 - val_accuracy: 0.7000\n",
      "Epoch 29/60\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 0.5777 - accuracy: 0.6618 - val_loss: 0.6798 - val_accuracy: 0.6333\n",
      "Epoch 30/60\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 0.5552 - accuracy: 0.7101 - val_loss: 0.6330 - val_accuracy: 0.6222\n",
      "Epoch 31/60\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.5656 - accuracy: 0.7343 - val_loss: 0.7377 - val_accuracy: 0.5667\n",
      "Epoch 32/60\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 0.5668 - accuracy: 0.6763 - val_loss: 0.6287 - val_accuracy: 0.6667\n",
      "Epoch 33/60\n",
      "7/7 [==============================] - 1s 186ms/step - loss: 0.5523 - accuracy: 0.7150 - val_loss: 0.6187 - val_accuracy: 0.6556\n",
      "Epoch 34/60\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.5396 - accuracy: 0.7005 - val_loss: 0.6418 - val_accuracy: 0.6333\n",
      "Epoch 35/60\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 0.5351 - accuracy: 0.7198 - val_loss: 0.6804 - val_accuracy: 0.6444\n",
      "Epoch 36/60\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.5550 - accuracy: 0.7391 - val_loss: 0.6762 - val_accuracy: 0.6000\n",
      "Epoch 37/60\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 0.5712 - accuracy: 0.7053 - val_loss: 0.6543 - val_accuracy: 0.6778\n",
      "Epoch 38/60\n",
      "7/7 [==============================] - 1s 174ms/step - loss: 0.5781 - accuracy: 0.6957 - val_loss: 0.6608 - val_accuracy: 0.6222\n",
      "Epoch 39/60\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 0.5557 - accuracy: 0.7150 - val_loss: 0.6214 - val_accuracy: 0.6667\n",
      "Epoch 40/60\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 0.6078 - accuracy: 0.6667 - val_loss: 0.6418 - val_accuracy: 0.6556\n",
      "Epoch 41/60\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 0.5345 - accuracy: 0.7343 - val_loss: 0.6328 - val_accuracy: 0.6444\n",
      "Epoch 42/60\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 0.5663 - accuracy: 0.7198 - val_loss: 0.7467 - val_accuracy: 0.5667\n",
      "Epoch 43/60\n",
      "7/7 [==============================] - 1s 199ms/step - loss: 0.5461 - accuracy: 0.7440 - val_loss: 0.6134 - val_accuracy: 0.6556\n",
      "Epoch 44/60\n",
      "7/7 [==============================] - 1s 194ms/step - loss: 0.5376 - accuracy: 0.7198 - val_loss: 0.6122 - val_accuracy: 0.6778\n",
      "Epoch 45/60\n",
      "7/7 [==============================] - 1s 198ms/step - loss: 0.5586 - accuracy: 0.6763 - val_loss: 0.6211 - val_accuracy: 0.6444\n",
      "Epoch 46/60\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.5256 - accuracy: 0.7246 - val_loss: 0.5981 - val_accuracy: 0.7222\n",
      "Epoch 47/60\n",
      "7/7 [==============================] - 1s 173ms/step - loss: 0.5378 - accuracy: 0.7391 - val_loss: 0.6188 - val_accuracy: 0.6778\n",
      "Epoch 48/60\n",
      "7/7 [==============================] - 1s 170ms/step - loss: 0.5107 - accuracy: 0.7488 - val_loss: 0.6305 - val_accuracy: 0.6556\n",
      "Epoch 49/60\n",
      "7/7 [==============================] - 1s 170ms/step - loss: 0.5435 - accuracy: 0.7198 - val_loss: 0.6578 - val_accuracy: 0.6556\n",
      "Epoch 50/60\n",
      "7/7 [==============================] - 1s 172ms/step - loss: 0.5370 - accuracy: 0.7198 - val_loss: 0.6313 - val_accuracy: 0.6778\n",
      "Epoch 51/60\n",
      "7/7 [==============================] - 1s 171ms/step - loss: 0.5061 - accuracy: 0.7246 - val_loss: 0.6572 - val_accuracy: 0.6444\n",
      "Epoch 52/60\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 0.5404 - accuracy: 0.7101 - val_loss: 0.7191 - val_accuracy: 0.6111\n",
      "Epoch 53/60\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.5286 - accuracy: 0.7536 - val_loss: 0.6481 - val_accuracy: 0.6556\n",
      "Epoch 54/60\n",
      "7/7 [==============================] - 1s 170ms/step - loss: 0.5444 - accuracy: 0.7198 - val_loss: 0.6495 - val_accuracy: 0.6778\n",
      "Epoch 55/60\n",
      "7/7 [==============================] - 1s 171ms/step - loss: 0.4954 - accuracy: 0.7536 - val_loss: 0.6145 - val_accuracy: 0.6778\n",
      "Epoch 56/60\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 0.5131 - accuracy: 0.7585 - val_loss: 0.5871 - val_accuracy: 0.6778\n",
      "Epoch 57/60\n",
      "7/7 [==============================] - 1s 169ms/step - loss: 0.4865 - accuracy: 0.7874 - val_loss: 0.6287 - val_accuracy: 0.7111\n",
      "Epoch 58/60\n",
      "7/7 [==============================] - 1s 172ms/step - loss: 0.4971 - accuracy: 0.7536 - val_loss: 0.7231 - val_accuracy: 0.6444\n",
      "Epoch 59/60\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 0.4850 - accuracy: 0.7633 - val_loss: 0.7127 - val_accuracy: 0.6333\n",
      "Epoch 60/60\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 0.5013 - accuracy: 0.7681 - val_loss: 0.6536 - val_accuracy: 0.6444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1ca71029f10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    datagen.flow(pedro_train_images, pedro_train_labels, batch_size=32),\n",
    "    epochs=60, batch_size=32,\n",
    "    validation_data=(pedro_test_images, pedro_test_labels),\n",
    "    steps_per_epoch=int(np.ceil(len(pedro_train_images) / float(32))),\n",
    "    validation_steps=int(np.ceil(len(pedro_test_images) / float(32)))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos los resultados del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 33ms/step\n",
      "Resultados para Pedro:\n",
      "Precisión: 0.6444444444444445\n",
      "F1 Score: 0.673469387755102\n",
      "Matriz de confusión:\n",
      "[[25 16]\n",
      " [16 33]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el modelo\n",
    "pedro_test_predictions = model.predict(pedro_test_images)\n",
    "pedro_test_predictions_rounded = np.round(pedro_test_predictions)\n",
    "\n",
    "pedro_accuracy = accuracy_score(pedro_test_labels, pedro_test_predictions_rounded)\n",
    "pedro_f1 = f1_score(pedro_test_labels, pedro_test_predictions_rounded)\n",
    "confusion_pedro = confusion_matrix(pedro_test_labels, pedro_test_predictions_rounded)\n",
    "\n",
    "# Mostramos los resultados\n",
    "print(\"Resultados para Pedro:\")\n",
    "print(\"Precisión:\", pedro_accuracy)\n",
    "print(\"F1 Score:\", pedro_f1)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(confusion_pedro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos nuevamente el modelo con las imágenes de Will Smith y Pedro Pascal, para comprobar si el modelo \"recuerda\" el entrenamiento previo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 25ms/step\n",
      "Resultados para Will:\n",
      "Precisión: 0.6555555555555556\n",
      "F1 Score: 0.6593406593406593\n",
      "Matriz de confusión:\n",
      "[[29 14]\n",
      " [17 30]]\n",
      "3/3 [==============================] - 0s 33ms/step\n",
      "Resultados para Bella:\n",
      "Precisión: 0.6444444444444445\n",
      "F1 Score: 0.5897435897435898\n",
      "Matriz de confusión:\n",
      "[[35  9]\n",
      " [23 23]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos nuevamente el modelo para Will Smith\n",
    "will_test_predictions = model.predict(will_test_images)\n",
    "will_test_predictions_rounded = np.round(will_test_predictions)\n",
    "\n",
    "will_accuracy = accuracy_score(will_test_labels, will_test_predictions_rounded)\n",
    "will_f1 = f1_score(will_test_labels, will_test_predictions_rounded)\n",
    "will_confusion = confusion_matrix(will_test_labels, will_test_predictions_rounded)\n",
    "\n",
    "print(\"Resultados para Will:\")\n",
    "print(\"Precisión:\", will_accuracy)\n",
    "print(\"F1 Score:\", will_f1)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(will_confusion)\n",
    "\n",
    "# Hacemos lo mismo con Bella Ramsey\n",
    "bella_test_predictions = model.predict(bella_test_images)\n",
    "bella_test_predictions_rounded = np.round(bella_test_predictions)\n",
    "\n",
    "bella_accuracy = accuracy_score(bella_test_labels, bella_test_predictions_rounded)\n",
    "bella_f1 = f1_score(bella_test_labels, bella_test_predictions_rounded)\n",
    "confusion_bella = confusion_matrix(bella_test_labels, bella_test_predictions_rounded)\n",
    "\n",
    "print(\"Resultados para Bella:\")\n",
    "print(\"Precisión:\", bella_accuracy)\n",
    "print(\"F1 Score:\", bella_f1)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(confusion_bella)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#77dd77;\">Conclusiones</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No parece haber un patrón claro de resultados que esté relacionado con el orden en el que se intentar detectar los actores. Todo parece indicar que Bella Ramsey, en general, tiene mejores resultados, independientemente del orden; así como Pedro Pascal tiene unos resultados peores. El motivo, puesto que se ha cambiado el orden y, por norma general, se sigue este patrón, parece ser que las imágenes de Bella son más indicadas para esta tarea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otro lado, los resultados a la hora de detectar la presencia de Will y Bella, después de haber entrenado el modelo con imágenes de Pedro, son relativamente buenos. A pesar de que Bella suele tener mejores resultados que Will, en esta ocasión ha tenido un resultado ligeramente inferior. Lo más probable es que el motivo se deba a que el modelo se entrenó en primer lugar con imágenes suyas, y luego con las de Will, por lo que ha tenido más tiempo para \"olvidarla\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La conclusión principal a la que llego tras ver los resultados es que no debo reentrenar un modelo con imágenes de otros actores. En lugar de comenzar con pesos aleatorios, a partir del segundo entrenamiento el modelo puede comenzar sesgado hacia el entrenamiento anterior, ya que parte de los pesos ajustados para la detección del actor anterior. El experimento me sigue llevando a la idea de que el enfoque 1-1 es el más conveniente, pero creando un modelo para cada actor, no reentrenando un mismo modelo una y otra vez, ya que los resultados pueden ser impredecibles."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
